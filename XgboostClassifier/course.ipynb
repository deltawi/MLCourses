{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_41</th>\n",
       "      <th>feature_42</th>\n",
       "      <th>feature_43</th>\n",
       "      <th>feature_44</th>\n",
       "      <th>feature_45</th>\n",
       "      <th>feature_46</th>\n",
       "      <th>feature_47</th>\n",
       "      <th>feature_48</th>\n",
       "      <th>feature_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0          0          0          1          0          1          0   \n",
       "1   1          0          0          0          0          2          1   \n",
       "2   2          0          0          0          0          0          0   \n",
       "3   3          0          0          0          0          0          0   \n",
       "4   4          0          0          0          0          0          0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  ...  feature_41  feature_42  feature_43  \\\n",
       "0          0          0          0  ...           0           0          21   \n",
       "1          0          0          0  ...           0           0           0   \n",
       "2          0          0          0  ...           0           1           0   \n",
       "3          0          3          0  ...           0           0           0   \n",
       "4          0          0          0  ...           0           0           0   \n",
       "\n",
       "   feature_44  feature_45  feature_46  feature_47  feature_48  feature_49  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0          13           2           0   \n",
       "3           0           0           0           0           1           0   \n",
       "4           0           0           0           0           1           0   \n",
       "\n",
       "    target  \n",
       "0  Class_2  \n",
       "1  Class_1  \n",
       "2  Class_1  \n",
       "3  Class_4  \n",
       "4  Class_2  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 52 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   id          100000 non-null  int64 \n",
      " 1   feature_0   100000 non-null  int64 \n",
      " 2   feature_1   100000 non-null  int64 \n",
      " 3   feature_2   100000 non-null  int64 \n",
      " 4   feature_3   100000 non-null  int64 \n",
      " 5   feature_4   100000 non-null  int64 \n",
      " 6   feature_5   100000 non-null  int64 \n",
      " 7   feature_6   100000 non-null  int64 \n",
      " 8   feature_7   100000 non-null  int64 \n",
      " 9   feature_8   100000 non-null  int64 \n",
      " 10  feature_9   100000 non-null  int64 \n",
      " 11  feature_10  100000 non-null  int64 \n",
      " 12  feature_11  100000 non-null  int64 \n",
      " 13  feature_12  100000 non-null  int64 \n",
      " 14  feature_13  100000 non-null  int64 \n",
      " 15  feature_14  100000 non-null  int64 \n",
      " 16  feature_15  100000 non-null  int64 \n",
      " 17  feature_16  100000 non-null  int64 \n",
      " 18  feature_17  100000 non-null  int64 \n",
      " 19  feature_18  100000 non-null  int64 \n",
      " 20  feature_19  100000 non-null  int64 \n",
      " 21  feature_20  100000 non-null  int64 \n",
      " 22  feature_21  100000 non-null  int64 \n",
      " 23  feature_22  100000 non-null  int64 \n",
      " 24  feature_23  100000 non-null  int64 \n",
      " 25  feature_24  100000 non-null  int64 \n",
      " 26  feature_25  100000 non-null  int64 \n",
      " 27  feature_26  100000 non-null  int64 \n",
      " 28  feature_27  100000 non-null  int64 \n",
      " 29  feature_28  100000 non-null  int64 \n",
      " 30  feature_29  100000 non-null  int64 \n",
      " 31  feature_30  100000 non-null  int64 \n",
      " 32  feature_31  100000 non-null  int64 \n",
      " 33  feature_32  100000 non-null  int64 \n",
      " 34  feature_33  100000 non-null  int64 \n",
      " 35  feature_34  100000 non-null  int64 \n",
      " 36  feature_35  100000 non-null  int64 \n",
      " 37  feature_36  100000 non-null  int64 \n",
      " 38  feature_37  100000 non-null  int64 \n",
      " 39  feature_38  100000 non-null  int64 \n",
      " 40  feature_39  100000 non-null  int64 \n",
      " 41  feature_40  100000 non-null  int64 \n",
      " 42  feature_41  100000 non-null  int64 \n",
      " 43  feature_42  100000 non-null  int64 \n",
      " 44  feature_43  100000 non-null  int64 \n",
      " 45  feature_44  100000 non-null  int64 \n",
      " 46  feature_45  100000 non-null  int64 \n",
      " 47  feature_46  100000 non-null  int64 \n",
      " 48  feature_47  100000 non-null  int64 \n",
      " 49  feature_48  100000 non-null  int64 \n",
      " 50  feature_49  100000 non-null  int64 \n",
      " 51  target      100000 non-null  object\n",
      "dtypes: int64(51), object(1)\n",
      "memory usage: 39.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       id   100000  [0 1 2]\n",
      "                feature_0       11  [0 1 9]\n",
      "                feature_1       31  [0 1 6]\n",
      "                feature_2        7  [1 0 3]\n",
      "                feature_3       26  [0 1 2]\n",
      "                feature_4       38  [1 2 0]\n",
      "                feature_5       11  [0 1 2]\n",
      "                feature_6       28  [0 3 2]\n",
      "                feature_7       32  [ 0  3 13]\n",
      "                feature_8       37  [ 0 15  1]\n",
      "                feature_9       18  [0 2 6]\n",
      "               feature_10       17  [ 0  2 10]\n",
      "               feature_11       13  [0 1 3]\n",
      "               feature_12       12  [0 1 2]\n",
      "               feature_13        4  [0 1 2]\n",
      "               feature_14       52  [0 1 7]\n",
      "               feature_15       21  [ 0  3 11]\n",
      "               feature_16       20  [0 1 9]\n",
      "               feature_17       17  [6 3 0]\n",
      "               feature_18       14  [0 3 4]\n",
      "               feature_19       58  [ 0  1 28]\n",
      "               feature_20       18  [0 2 3]\n",
      "               feature_21       36  [0 5 2]\n",
      "               feature_22        5  [0 2 1]\n",
      "               feature_23       20  [0 1 4]\n",
      "               feature_24       35  [ 0  1 10]\n",
      "               feature_25       23  [0 6 2]\n",
      "               feature_26       22  [0 1 8]\n",
      "               feature_27       32  [0 5 1]\n",
      "               feature_28       24  [0 2 1]\n",
      "               feature_29       14  [0 1 2]\n",
      "               feature_30       43  [1 0 2]\n",
      "               feature_31       46  [0 1 3]\n",
      "               feature_32       30  [0 2 1]\n",
      "               feature_33       25  [ 0 19  1]\n",
      "               feature_34       26  [1 0 2]\n",
      "               feature_35       44  [0 1 7]\n",
      "               feature_36        4  [0 1 2]\n",
      "               feature_37       15  [0 7 1]\n",
      "               feature_38       71  [0 3 4]\n",
      "               feature_39       70  [ 0  1 13]\n",
      "               feature_40       22  [3 0 2]\n",
      "               feature_41       31  [0 1 7]\n",
      "               feature_42       40  [0 1 4]\n",
      "               feature_43       33  [21  0  2]\n",
      "               feature_44       10  [0 1 7]\n",
      "               feature_45       27  [0 1 2]\n",
      "               feature_46       30  [0 2 1]\n",
      "               feature_47       26  [ 0 13  2]\n",
      "               feature_48       45  [0 2 1]\n",
      "               feature_49       21  [0 1 3]\n",
      "                   target        4  ['Class_2' 'Class_1' 'Class_4']\n"
     ]
    }
   ],
   "source": [
    "for col in train_df.columns:\n",
    "    print(\"% 25s\" % col, \" % 7d \" % train_df[col].nunique(), train_df[col].unique()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_n_iterations(pipeline, x_train, lbl_train, cols_used,\n",
    "                          n_splits=2, groups_split=None,\n",
    "                          nseed=1, verbose=True, fit_params=None):\n",
    "    \"\"\"\n",
    "    :param pipeline: transformation pipeline. It has to be compatible with sklearn API\n",
    "    :param x_train: training set\n",
    "    :param y_train: training target\n",
    "    :param n_splits: number of splits for crossvalidation\n",
    "    :param n_jobs: number of CPUs to use in cross_validate function\n",
    "    :param groups_split: columns to use in case of Groups split cv\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=n_splits, test_size=0.3, random_state=0)\n",
    "    \n",
    "    x_train.drop(groups_split, axis=1, inplace=True)\n",
    "    \n",
    "    n_estimators = []\n",
    "    scores = []\n",
    "    for train_idx, valid_idx in cv.split(x_train, lbl_train):\n",
    "        train_i = x_train.iloc[train_idx]\n",
    "        valid_i = x_train.iloc[valid_idx]\n",
    "        y_train_i = lbl_train[train_idx]\n",
    "        y_valid_i = lbl_train[valid_idx]\n",
    "        print(train_i.loc[:, cols_used].shape, valid_i.loc[:, cols_used].shape)\n",
    "        #print(f\"Train pos: %6d\" %sum(y_train_i), \", neg: %7d\" %(len(y_train_i) - sum(y_train_i)))\n",
    "        #print(f\"validation pos: %6d\" %sum(y_valid_i), \", neg: %7d\" %(len(y_valid_i) - sum(y_valid_i)))\n",
    "        \n",
    "        x_train_i = pipeline.fit_transform(train_i.loc[:, cols_used].copy(deep=True), y_train_i)\n",
    "        x_valid_i = pipeline.transform(valid_i.loc[:, cols_used].copy(deep=True))\n",
    "        \n",
    "        est = XGBClassifier(**fit_params, use_label_encoder=False)\n",
    "        \n",
    "        est.fit(x_train_i, y_train_i,\n",
    "                eval_set=[(x_train_i, y_train_i), (x_valid_i, y_valid_i)],\n",
    "                eval_metric=[\"mlogloss\"], verbose=500, early_stopping_rounds=50)\n",
    "        \n",
    "        n_estimators.append(est.best_iteration)\n",
    "        scores.append(est.best_score)\n",
    "        \n",
    "    print(\"Score CV : \", np.round(np.mean(scores), 5), ' +/-', np.std(scores)) \n",
    "    print(\"Early stopping result : \", str(n_estimators))\n",
    "    \n",
    "    return n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 1500,\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'n_jobs': 10,\n",
    "    'tree_method': 'hist'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from category_encoders.ordinal import OrdinalEncoder as OrdEncCE\n",
    "from sklearn.preprocessing import OrdinalEncoder as OrdEncSKl\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars_1 = ['feature_1', 'feature_2', 'feature_3']\n",
    "num_vars_1 = ['feature_4', 'feature_5', 'feature_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[('Enc', OrdEncCE(handle_unknown=\"missing\"))])\n",
    "numerical_transformer = Pipeline(steps=[('Scaler', StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(remainder='passthrough',\n",
    "    transformers=[\n",
    "        ('cat_vars_1', categorical_transformer, cat_vars_1),\n",
    "        ('num_vars_1', numerical_transformer, num_vars_1)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessing', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = OrdEncSKl().fit(train_df.target.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.38214\tvalidation_1-mlogloss:1.38221\n",
      "[300]\tvalidation_0-mlogloss:1.09478\tvalidation_1-mlogloss:1.10942\n",
      "[600]\tvalidation_0-mlogloss:1.07279\tvalidation_1-mlogloss:1.10050\n",
      "[900]\tvalidation_0-mlogloss:1.05972\tvalidation_1-mlogloss:1.09824\n",
      "[1200]\tvalidation_0-mlogloss:1.04949\tvalidation_1-mlogloss:1.09704\n",
      "[1499]\tvalidation_0-mlogloss:1.04161\tvalidation_1-mlogloss:1.09653\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.38212\tvalidation_1-mlogloss:1.38222\n",
      "[300]\tvalidation_0-mlogloss:1.09204\tvalidation_1-mlogloss:1.11370\n",
      "[600]\tvalidation_0-mlogloss:1.06977\tvalidation_1-mlogloss:1.10563\n",
      "[900]\tvalidation_0-mlogloss:1.05638\tvalidation_1-mlogloss:1.10338\n",
      "[1200]\tvalidation_0-mlogloss:1.04637\tvalidation_1-mlogloss:1.10249\n",
      "[1499]\tvalidation_0-mlogloss:1.03872\tvalidation_1-mlogloss:1.10206\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.38213\tvalidation_1-mlogloss:1.38222\n",
      "[300]\tvalidation_0-mlogloss:1.09330\tvalidation_1-mlogloss:1.11159\n",
      "[600]\tvalidation_0-mlogloss:1.07192\tvalidation_1-mlogloss:1.10303\n",
      "[900]\tvalidation_0-mlogloss:1.05873\tvalidation_1-mlogloss:1.10083\n",
      "[1200]\tvalidation_0-mlogloss:1.04849\tvalidation_1-mlogloss:1.09992\n",
      "[1499]\tvalidation_0-mlogloss:1.03982\tvalidation_1-mlogloss:1.09948\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.38215\tvalidation_1-mlogloss:1.38221\n",
      "[300]\tvalidation_0-mlogloss:1.09466\tvalidation_1-mlogloss:1.10896\n",
      "[600]\tvalidation_0-mlogloss:1.07209\tvalidation_1-mlogloss:1.10018\n",
      "[900]\tvalidation_0-mlogloss:1.05835\tvalidation_1-mlogloss:1.09837\n",
      "[1200]\tvalidation_0-mlogloss:1.04799\tvalidation_1-mlogloss:1.09783\n",
      "[1448]\tvalidation_0-mlogloss:1.04122\tvalidation_1-mlogloss:1.09773\n",
      "Score CV :  1.09895  +/- 0.0020805639860384468\n",
      "Early stopping result :  [1497, 1498, 1499, 1398]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1497, 1498, 1499, 1398]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_n_iterations(\n",
    "    pipeline=pipeline,\n",
    "    x_train=train_df.drop(['target'], axis=1).copy(),\n",
    "    lbl_train=target_encoder.transform(train_df.target.values.reshape(-1, 1)),\n",
    "    n_splits=4,\n",
    "    groups_split='id',\n",
    "    fit_params=params,\n",
    "    cols_used=train_df.drop(['id', 'target'], axis=1).columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37802\tvalidation_1-mlogloss:1.37815\n",
      "[500]\tvalidation_0-mlogloss:1.05594\tvalidation_1-mlogloss:1.09776\n",
      "[855]\tvalidation_0-mlogloss:1.03656\tvalidation_1-mlogloss:1.09642\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37795\tvalidation_1-mlogloss:1.37818\n",
      "[500]\tvalidation_0-mlogloss:1.05269\tvalidation_1-mlogloss:1.10295\n",
      "[926]\tvalidation_0-mlogloss:1.03036\tvalidation_1-mlogloss:1.10196\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37798\tvalidation_1-mlogloss:1.37817\n",
      "[500]\tvalidation_0-mlogloss:1.05491\tvalidation_1-mlogloss:1.10040\n",
      "[918]\tvalidation_0-mlogloss:1.03185\tvalidation_1-mlogloss:1.09940\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37805\tvalidation_1-mlogloss:1.37813\n",
      "[500]\tvalidation_0-mlogloss:1.05447\tvalidation_1-mlogloss:1.09811\n",
      "[702]\tvalidation_0-mlogloss:1.04230\tvalidation_1-mlogloss:1.09790\n",
      "Score CV :  1.09886  +/- 0.0020243627392342836\n",
      "Early stopping result :  [805, 876, 868, 652]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[805, 876, 868, 652]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_n_iterations(\n",
    "    pipeline=pipeline,\n",
    "    x_train=train_df.drop(['target'], axis=1).copy(),\n",
    "    lbl_train=target_encoder.transform(train_df.target.values.reshape(-1, 1)),\n",
    "    n_splits=4,\n",
    "    groups_split='id',\n",
    "    fit_params=params,\n",
    "    cols_used=train_df.drop(['id', 'target'], axis=1).columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37801\tvalidation_1-mlogloss:1.37815\n",
      "[500]\tvalidation_0-mlogloss:1.05213\tvalidation_1-mlogloss:1.09573\n",
      "[932]\tvalidation_0-mlogloss:1.02339\tvalidation_1-mlogloss:1.09418\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37798\tvalidation_1-mlogloss:1.37821\n",
      "[500]\tvalidation_0-mlogloss:1.05016\tvalidation_1-mlogloss:1.10130\n",
      "[887]\tvalidation_0-mlogloss:1.02435\tvalidation_1-mlogloss:1.10011\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37799\tvalidation_1-mlogloss:1.37817\n",
      "[500]\tvalidation_0-mlogloss:1.05123\tvalidation_1-mlogloss:1.09820\n",
      "[822]\tvalidation_0-mlogloss:1.02868\tvalidation_1-mlogloss:1.09692\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37803\tvalidation_1-mlogloss:1.37812\n",
      "[500]\tvalidation_0-mlogloss:1.05113\tvalidation_1-mlogloss:1.09623\n",
      "[769]\tvalidation_0-mlogloss:1.03174\tvalidation_1-mlogloss:1.09570\n",
      "Score CV :  1.09669  +/- 0.0021964477429477305\n",
      "Early stopping result :  [882, 838, 772, 720]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[882, 838, 772, 720]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_n_iterations(\n",
    "    pipeline=pipeline,\n",
    "    x_train=train_df.drop(['target'], axis=1).copy(),\n",
    "    lbl_train=target_encoder.transform(train_df.target.values.reshape(-1, 1)),\n",
    "    n_splits=4,\n",
    "    groups_split='id',\n",
    "    fit_params=params,\n",
    "    cols_used=train_df.drop(['id', 'target'], axis=1).columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37802\tvalidation_1-mlogloss:1.37815\n",
      "[500]\tvalidation_0-mlogloss:1.05309\tvalidation_1-mlogloss:1.09570\n",
      "[946]\tvalidation_0-mlogloss:1.02393\tvalidation_1-mlogloss:1.09412\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37799\tvalidation_1-mlogloss:1.37821\n",
      "[500]\tvalidation_0-mlogloss:1.05101\tvalidation_1-mlogloss:1.10129\n",
      "[908]\tvalidation_0-mlogloss:1.02439\tvalidation_1-mlogloss:1.09994\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37800\tvalidation_1-mlogloss:1.37817\n",
      "[500]\tvalidation_0-mlogloss:1.05195\tvalidation_1-mlogloss:1.09831\n",
      "[906]\tvalidation_0-mlogloss:1.02467\tvalidation_1-mlogloss:1.09695\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37803\tvalidation_1-mlogloss:1.37812\n",
      "[500]\tvalidation_0-mlogloss:1.05199\tvalidation_1-mlogloss:1.09613\n",
      "[818]\tvalidation_0-mlogloss:1.02986\tvalidation_1-mlogloss:1.09542\n",
      "Score CV :  1.09656  +/- 0.0021879600516233884\n",
      "Early stopping result :  [896, 858, 857, 769]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[896, 858, 857, 769]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_n_iterations(\n",
    "    pipeline=pipeline,\n",
    "    x_train=train_df.drop(['target'], axis=1).copy(),\n",
    "    lbl_train=target_encoder.transform(train_df.target.values.reshape(-1, 1)),\n",
    "    n_splits=4,\n",
    "    groups_split='id',\n",
    "    fit_params=params,\n",
    "    cols_used=train_df.drop(['id', 'target'], axis=1).columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37810\tvalidation_1-mlogloss:1.37817\n",
      "[500]\tvalidation_0-mlogloss:1.07206\tvalidation_1-mlogloss:1.09681\n",
      "[1000]\tvalidation_0-mlogloss:1.05072\tvalidation_1-mlogloss:1.09383\n",
      "[1114]\tvalidation_0-mlogloss:1.04674\tvalidation_1-mlogloss:1.09371\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37807\tvalidation_1-mlogloss:1.37825\n",
      "[500]\tvalidation_0-mlogloss:1.06982\tvalidation_1-mlogloss:1.10226\n",
      "[1000]\tvalidation_0-mlogloss:1.04869\tvalidation_1-mlogloss:1.09959\n",
      "[1275]\tvalidation_0-mlogloss:1.03955\tvalidation_1-mlogloss:1.09941\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37808\tvalidation_1-mlogloss:1.37820\n",
      "[500]\tvalidation_0-mlogloss:1.07095\tvalidation_1-mlogloss:1.09919\n",
      "[1000]\tvalidation_0-mlogloss:1.04944\tvalidation_1-mlogloss:1.09667\n",
      "[1203]\tvalidation_0-mlogloss:1.04240\tvalidation_1-mlogloss:1.09653\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37810\tvalidation_1-mlogloss:1.37816\n",
      "[500]\tvalidation_0-mlogloss:1.07137\tvalidation_1-mlogloss:1.09676\n",
      "[910]\tvalidation_0-mlogloss:1.05285\tvalidation_1-mlogloss:1.09507\n",
      "Score CV :  1.09616  +/- 0.002101347112568514\n",
      "Early stopping result :  [1064, 1225, 1154, 860]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1064, 1225, 1154, 860]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_n_iterations(\n",
    "    pipeline=pipeline,\n",
    "    x_train=train_df.drop(['target'], axis=1).copy(),\n",
    "    lbl_train=target_encoder.transform(train_df.target.values.reshape(-1, 1)),\n",
    "    n_splits=4,\n",
    "    groups_split='id',\n",
    "    fit_params=params,\n",
    "    cols_used=train_df.drop(['id', 'target'], axis=1).columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37816\tvalidation_1-mlogloss:1.37820\n",
      "[500]\tvalidation_0-mlogloss:1.08585\tvalidation_1-mlogloss:1.09871\n",
      "[1000]\tvalidation_0-mlogloss:1.07204\tvalidation_1-mlogloss:1.09423\n",
      "[1499]\tvalidation_0-mlogloss:1.06239\tvalidation_1-mlogloss:1.09303\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37812\tvalidation_1-mlogloss:1.37828\n",
      "[500]\tvalidation_0-mlogloss:1.08348\tvalidation_1-mlogloss:1.10423\n",
      "[1000]\tvalidation_0-mlogloss:1.06970\tvalidation_1-mlogloss:1.10021\n",
      "[1499]\tvalidation_0-mlogloss:1.06018\tvalidation_1-mlogloss:1.09926\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37814\tvalidation_1-mlogloss:1.37823\n",
      "[500]\tvalidation_0-mlogloss:1.08465\tvalidation_1-mlogloss:1.10118\n",
      "[1000]\tvalidation_0-mlogloss:1.07080\tvalidation_1-mlogloss:1.09713\n",
      "[1499]\tvalidation_0-mlogloss:1.06104\tvalidation_1-mlogloss:1.09621\n",
      "(70000, 50) (30000, 50)\n",
      "[0]\tvalidation_0-mlogloss:1.37815\tvalidation_1-mlogloss:1.37820\n",
      "[500]\tvalidation_0-mlogloss:1.08555\tvalidation_1-mlogloss:1.09837\n",
      "[1000]\tvalidation_0-mlogloss:1.07130\tvalidation_1-mlogloss:1.09505\n",
      "[1499]\tvalidation_0-mlogloss:1.06146\tvalidation_1-mlogloss:1.09451\n",
      "Score CV :  1.09575  +/- 0.0023161839709962798\n",
      "Early stopping result :  [1499, 1498, 1490, 1495]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1499, 1498, 1490, 1495]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_n_iterations(\n",
    "    pipeline=pipeline,\n",
    "    x_train=train_df.drop(['target'], axis=1).copy(),\n",
    "    lbl_train=target_encoder.transform(train_df.target.values.reshape(-1, 1)),\n",
    "    n_splits=4,\n",
    "    groups_split='id',\n",
    "    fit_params=params,\n",
    "    cols_used=train_df.drop(['id', 'target'], axis=1).columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
